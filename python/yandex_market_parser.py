"""
–ü–∞—Ä—Å–µ—Ä –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ —Å –Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ API, –∫–æ–≥–¥–∞ Partner API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
"""
import requests
import logging
import re
from typing import List, Optional
from datetime import datetime
from bs4 import BeautifulSoup

from data_providers import ProductData

logger = logging.getLogger(__name__)


class YandexMarketParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ —Å –Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç"""
    
    BASE_URL = "https://market.yandex.ru"
    
    def __init__(self, use_selenium: bool = False):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞
        
        Args:
            use_selenium: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Selenium –¥–ª—è —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ JavaScript (—Ç—Ä–µ–±—É–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏)
        """
        self.use_selenium = use_selenium
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1"
        }
        
        self.selenium_driver = None
        if use_selenium:
            try:
                from selenium import webdriver
                from selenium.webdriver.chrome.options import Options
                from selenium.webdriver.chrome.service import Service
                from selenium.webdriver.common.by import By
                from selenium.webdriver.support.ui import WebDriverWait
                from selenium.webdriver.support import expected_conditions as EC
                
                chrome_options = Options()
                chrome_options.add_argument('--headless')
                chrome_options.add_argument('--no-sandbox')
                chrome_options.add_argument('--disable-dev-shm-usage')
                chrome_options.add_argument('--disable-gpu')
                chrome_options.add_argument('--disable-blink-features=AutomationControlled')
                chrome_options.add_argument(f'user-agent={self.headers["User-Agent"]}')
                chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
                chrome_options.add_experimental_option('useAutomationExtension', False)
                
                # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å webdriver-manager –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –¥—Ä–∞–π–≤–µ—Ä–∞
                try:
                    from webdriver_manager.chrome import ChromeDriverManager
                    service = Service(ChromeDriverManager().install())
                    self.selenium_driver = webdriver.Chrome(service=service, options=chrome_options)
                    logger.info("‚úÖ Selenium WebDriver –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (—Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–æ–π –¥—Ä–∞–π–≤–µ—Ä–∞)")
                except ImportError:
                    # –ï—Å–ª–∏ webdriver-manager –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–π ChromeDriver
                    logger.info("webdriver-manager –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–π ChromeDriver")
                    self.selenium_driver = webdriver.Chrome(options=chrome_options)
                    logger.info("‚úÖ Selenium WebDriver –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–Ω—ã–π –¥—Ä–∞–π–≤–µ—Ä)")
            except Exception as e:
                logger.warning(f"Selenium –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}. –ò—Å–ø–æ–ª—å–∑—É—é –æ–±—ã—á–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥.")
                logger.warning("–î–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ Selenium –≤—ã–ø–æ–ª–Ω–∏—Ç–µ: pip install selenium webdriver-manager")
                logger.warning("–¢–∞–∫–∂–µ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω Google Chrome")
                self.use_selenium = False
    
    def search_products(self, query: str, limit: int = 10) -> List[ProductData]:
        """
        –ü–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ –Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ ProductData
        """
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º URL –ø–æ–∏—Å–∫–∞
            search_url = f"{self.BASE_URL}/search"
            params = {
                "text": query,
                "how": "aprice",  # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Ü–µ–Ω–µ (–æ—Ç –¥–µ—à–µ–≤—ã—Ö –∫ –¥–æ—Ä–æ–≥–∏–º)
                "local-offers-first": "0",  # –ù–µ –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                "onstock": "1"  # –¢–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä—ã –≤ –Ω–∞–ª–∏—á–∏–∏
            }
            
            logger.info(f"üîç –ü–∞—Ä—Å–∏–Ω–≥ —Ç–æ–≤–∞—Ä–æ–≤ —Å –Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç: –∑–∞–ø—Ä–æ—Å '{query}'")
            logger.info(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Ü–µ–Ω–µ, —Ç–æ–ª—å–∫–æ –≤ –Ω–∞–ª–∏—á–∏–∏")
            
            html_content = None
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Selenium –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
            if self.use_selenium and self.selenium_driver:
                try:
                    logger.info("üåê –ò—Å–ø–æ–ª—å–∑—É—é Selenium –¥–ª—è —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ JavaScript...")
                    # –ö–æ–¥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è URL
                    import urllib.parse
                    encoded_query = urllib.parse.quote(query)
                    full_url = f"{search_url}?text={encoded_query}&how=aprice&local-offers-first=0"
                    logger.info(f"   –û—Ç–∫—Ä—ã–≤–∞—é URL: {full_url}")
                    
                    self.selenium_driver.get(full_url)
                    
                    # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                    from selenium.webdriver.support.ui import WebDriverWait
                    from selenium.webdriver.support import expected_conditions as EC
                    from selenium.webdriver.common.by import By
                    
                    try:
                        logger.info("   –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤...")
                        WebDriverWait(self.selenium_driver, 15).until(
                            EC.presence_of_element_located((By.CSS_SELECTOR, "[data-zone-name*='product'], [data-zone-name*='snippet'], [data-zone-name*='offer']"))
                        )
                        logger.info("   –¢–æ–≤–∞—Ä—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
                    except Exception as e:
                        logger.warning(f"   –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {e}, –ø—Ä–æ–¥–æ–ª–∂–∞—é...")
                        # –î–∞–µ–º –µ—â–µ –Ω–µ–º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É
                        import time
                        time.sleep(2)
                    
                    html_content = self.selenium_driver.page_source
                    logger.info(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —á–µ—Ä–µ–∑ Selenium, —Ä–∞–∑–º–µ—Ä HTML: {len(html_content)} —Å–∏–º–≤–æ–ª–æ–≤")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Selenium: {e}, –ø—Ä–æ–±—É—é –æ–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å", exc_info=True)
            
            # –ï—Å–ª–∏ Selenium –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è –∏–ª–∏ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º requests
            if not html_content:
                try:
                    import urllib.parse
                    encoded_query = urllib.parse.quote(query)
                    full_url = f"{search_url}?text={encoded_query}&how=aprice&local-offers-first=0"
                    logger.info(f"üì° –û—Ç–ø—Ä–∞–≤–∫–∞ HTTP –∑–∞–ø—Ä–æ—Å–∞ –∫ –Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç...")
                    logger.info(f"   URL: {full_url}")
                    
                    response = requests.get(full_url, headers=self.headers, timeout=20, allow_redirects=True)
                    
                    if response.status_code != 200:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: HTTP {response.status_code}")
                        logger.error(f"   –û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞ (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {response.text[:500]}")
                        return []
                    
                    html_content = response.text
                    logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω HTML –∫–æ–Ω—Ç–µ–Ω—Ç, —Ä–∞–∑–º–µ—Ä: {len(html_content)} —Å–∏–º–≤–æ–ª–æ–≤")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –≤–µ—Ä–Ω—É–ª–∞—Å—å –ª–∏ –∫–∞–ø—á–∞ –∏–ª–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞
                    if 'captcha' in html_content.lower() or '—Ä–æ–±–æ—Ç' in html_content.lower():
                        logger.warning("‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω–æ, –Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç —Ç—Ä–µ–±—É–µ—Ç –∫–∞–ø—á—É. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Selenium.")
                    if len(html_content) < 1000:
                        logger.warning(f"‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–π HTML ({len(html_content)} —Å–∏–º–≤–æ–ª–æ–≤), –≤–æ–∑–º–æ–∂–Ω–æ, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å")
                except requests.exceptions.Timeout:
                    logger.error("–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ –Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç")
                    return []
                except requests.exceptions.ConnectionError as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç: {e}")
                    return []
                except requests.exceptions.RequestException as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ –Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç: {e}")
                    return []
            
            # –ü–∞—Ä—Å–∏–º HTML
            if not html_content or len(html_content) < 100:
                logger.warning("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π HTML –∫–æ–Ω—Ç–µ–Ω—Ç")
                return []
            
            soup = BeautifulSoup(html_content, 'html.parser')
            products = []
            
            logger.info(f"HTML —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω, –∏—â–µ–º —Ç–æ–≤–∞—Ä—ã...")
            
            # –ú–µ—Ç–æ–¥ 1: –ü–æ–∏—Å–∫ –¥–∞–Ω–Ω—ã—Ö –≤ JSON (—á–∞—Å—Ç–æ –Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç –≤—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ script —Ç–µ–≥–∏)
            json_products = self._extract_from_json(soup)
            if json_products:
                logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(json_products)} —Ç–æ–≤–∞—Ä–æ–≤ –≤ JSON –¥–∞–Ω–Ω—ã—Ö")
                products.extend(json_products[:limit])
            
            # –ú–µ—Ç–æ–¥ 2: –ü–æ–∏—Å–∫ –≤ HTML —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
            product_elements = []
            if len(products) < limit:
                product_elements = self._find_product_elements(soup)
                logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(product_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤ –≤ HTML")
            
            # –ü–∞—Ä—Å–∏–º —ç–ª–µ–º–µ–Ω—Ç—ã —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ HTML
            parsed_count = 0
            failed_count = 0
            for element in product_elements[:limit * 2]:  # –ü—Ä–æ–±—É–µ–º –±–æ–ª—å—à–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤, —Ç.–∫. –Ω–µ –≤—Å–µ –º–æ–≥—É—Ç —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å—Å—è
                try:
                    product = self._parse_product_element(element, query)
                    if product:
                        if product not in products:  # –ò–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
                            products.append(product)
                            parsed_count += 1
                            logger.debug(f"–£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω —Ç–æ–≤–∞—Ä: {product.title[:50]}")
                        if len(products) >= limit:
                            break
                    else:
                        failed_count += 1
                except Exception as e:
                    failed_count += 1
                    logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —ç–ª–µ–º–µ–Ω—Ç–∞ —Ç–æ–≤–∞—Ä–∞: {e}")
                    continue
            
            if parsed_count == 0 and failed_count > 0:
                logger.warning(f"–ù–∞–π–¥–µ–Ω–æ {len(product_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ")
                logger.warning("–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
                logger.warning("  1. –ò–∑–º–µ–Ω–∏–ª–∞—Å—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ HTML –Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç")
                logger.warning("  2. –≠–ª–µ–º–µ–Ω—Ç—ã –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–∑–≤–∞–Ω–∏–µ, —Ü–µ–Ω–∞)")
                logger.warning("  3. –¢—Ä–µ–±—É–µ—Ç—Å—è JavaScript –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö (–Ω—É–∂–µ–Ω Selenium)")
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
            seen_titles = set()
            unique_products = []
            for product in products:
                if product.title not in seen_titles:
                    seen_titles.add(product.title)
                    unique_products.append(product)
            products = unique_products
            
            if products:
                logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")
            else:
                logger.warning("=" * 80)
                logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ç–æ–≤–∞—Ä—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ. –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
                logger.warning("   1. –ò–∑–º–µ–Ω–∏–ª–∞—Å—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ HTML –Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç")
                logger.warning("   2. –°—Ç—Ä–∞–Ω–∏—Ü–∞ —Ç—Ä–µ–±—É–µ—Ç JavaScript (–Ω—É–∂–µ–Ω Selenium)")
                logger.warning("   3. –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã –Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç")
                logger.warning("   4. –°—Ç—Ä–∞–Ω–∏—Ü–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–∞–ø—á—É –∏–ª–∏ —Ç—Ä–µ–±—É–µ—Ç –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é")
                logger.warning("=" * 80)
                
                # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                logger.debug(f"–†–∞–∑–º–µ—Ä HTML: {len(html_content)} —Å–∏–º–≤–æ–ª–æ–≤")
                logger.debug(f"–ù–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞: {len(product_elements)}")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (–ø–µ—Ä–≤—ã–µ 5000 —Å–∏–º–≤–æ–ª–æ–≤)
                if len(html_content) > 0:
                    logger.debug(f"HTML –∫–æ–Ω—Ç–µ–Ω—Ç (–ø–µ—Ä–≤—ã–µ 5000 —Å–∏–º–≤–æ–ª–æ–≤):\n{html_content[:5000]}")
                    
                    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ HTML
                    if 'product' in html_content.lower():
                        logger.debug("‚úÖ –í HTML –Ω–∞–π–¥–µ–Ω–æ —Å–ª–æ–≤–æ 'product'")
                    if 'offer' in html_content.lower():
                        logger.debug("‚úÖ –í HTML –Ω–∞–π–¥–µ–Ω–æ —Å–ª–æ–≤–æ 'offer'")
                    if 'snippet' in html_content.lower():
                        logger.debug("‚úÖ –í HTML –Ω–∞–π–¥–µ–Ω–æ —Å–ª–æ–≤–æ 'snippet'")
                    if 'data-zone-name' in html_content:
                        logger.debug("‚úÖ –í HTML –Ω–∞–π–¥–µ–Ω—ã data-zone-name –∞—Ç—Ä–∏–±—É—Ç—ã")
                    else:
                        logger.warning("‚ö†Ô∏è –í HTML –ù–ï –Ω–∞–π–¥–µ–Ω—ã data-zone-name –∞—Ç—Ä–∏–±—É—Ç—ã - –≤–æ–∑–º–æ–∂–Ω–æ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å")
            
            return products
            
        except requests.exceptions.RequestException as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ –Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç: {e}")
            return []
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}", exc_info=True)
            return []
        finally:
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º Selenium –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏
            if self.use_selenium and self.selenium_driver:
                try:
                    self.selenium_driver.quit()
                except:
                    pass
    
    def _extract_from_json(self, soup: BeautifulSoup) -> List[ProductData]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ JSON –¥–∞–Ω–Ω—ã—Ö, –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –≤ HTML"""
        products = []
        try:
            import json
            
            # –ò—â–µ–º script —Ç–µ–≥–∏ —Å JSON –¥–∞–Ω–Ω—ã–º–∏
            scripts = soup.find_all('script', type='application/json')
            scripts.extend(soup.find_all('script', string=re.compile(r'window\.__INITIAL_STATE__|__APP_DATA__|products|offers', re.I)))
            
            for script in scripts:
                try:
                    # –ü—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å JSON
                    if script.string:
                        # –ò—â–µ–º JSON –æ–±—ä–µ–∫—Ç—ã –≤ —Ç–µ–∫—Å—Ç–µ
                        json_matches = re.findall(r'\{[^{}]*"products"[^{}]*\}', script.string, re.DOTALL)
                        for match in json_matches:
                            try:
                                data = json.loads(match)
                                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ç–æ–≤–∞—Ä—ã –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
                                if 'products' in data:
                                    for item in data['products']:
                                        product = self._parse_json_product(item)
                                        if product:
                                            products.append(product)
                            except:
                                continue
                except:
                    continue
            
            # –¢–∞–∫–∂–µ –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ –≤ data-–∞—Ç—Ä–∏–±—É—Ç–∞—Ö
            data_attrs = soup.find_all(attrs={"data-state": True})
            for elem in data_attrs:
                try:
                    state = json.loads(elem.get('data-state', '{}'))
                    if 'products' in state or 'offers' in state:
                        items = state.get('products', state.get('offers', []))
                        for item in items:
                            product = self._parse_json_product(item)
                            if product:
                                products.append(product)
                except:
                    continue
                    
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–∑ JSON: {e}")
        
        return products
    
    def _parse_json_product(self, item: dict) -> Optional[ProductData]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ç–æ–≤–∞—Ä–∞ –∏–∑ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        try:
            title = item.get('name') or item.get('title') or item.get('offerName', '')
            if not title:
                return None
            
            # –¶–µ–Ω–∞
            price = 0
            price_data = item.get('price', {})
            if isinstance(price_data, dict):
                price = float(price_data.get('value', 0) or price_data.get('amount', 0))
            elif price_data:
                price = float(price_data)
            
            if price <= 0:
                return None
            
            # URL
            url = item.get('url') or item.get('link') or item.get('offerUrl', '')
            if url and not url.startswith('http'):
                url = f"{self.BASE_URL}{url}" if url.startswith('/') else f"{self.BASE_URL}/{url}"
            
            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = ""
            if 'pictures' in item and item['pictures']:
                image = item['pictures'][0].get('url', '') or item['pictures'][0].get('original', '')
            elif 'image' in item:
                image = item['image']
            
            # –ë—Ä–µ–Ω–¥ –∏ –º–æ–¥–µ–ª—å
            brand = item.get('vendor', {}).get('name', '') if isinstance(item.get('vendor'), dict) else (item.get('vendor') or '')
            model = item.get('model', {}).get('name', '') if isinstance(item.get('model'), dict) else (item.get('model') or '')
            
            # –ï—Å–ª–∏ –Ω–µ—Ç –±—Ä–µ–Ω–¥–∞, –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è
            if not brand:
                common_brands = ["Samsung", "Apple", "Xiaomi", "Huawei", "OnePlus", "Google", "Sony", "LG", "ASUS", "Lenovo"]
                for b in common_brands:
                    if b.lower() in title.lower():
                        brand = b
                        break
            
            return ProductData(
                title=title,
                brand=brand or "–ù–µ —É–∫–∞–∑–∞–Ω",
                model=model or "–ù–µ —É–∫–∞–∑–∞–Ω–∞",
                price=price,
                shop_name="–Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç",
                url=url or f"{self.BASE_URL}/search",
                image=image,
                description=item.get('description', ''),
                product_id=str(item.get('id', '')),
                scraped_at=datetime.utcnow()
            )
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON —Ç–æ–≤–∞—Ä–∞: {e}")
            return None
    
    def _find_product_elements(self, soup: BeautifulSoup) -> List:
        """–ü–æ–∏—Å–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤ –≤ HTML"""
        elements = []
        
        # –ú–µ—Ç–æ–¥ 1: –ü–æ–∏—Å–∫ –ø–æ data-–∞—Ç—Ä–∏–±—É—Ç–∞–º (—Å–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ –ø–æ–¥—Ö–æ–¥, —á—Ç–æ –∏ yandex_market_oauth_api
        data_zone_elements = soup.find_all(attrs={"data-zone-name": lambda x: x and "product" in x.lower()})
        if data_zone_elements:
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(data_zone_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –ø–æ data-zone-name")
            elements.extend(data_zone_elements)
        
        # –ú–µ—Ç–æ–¥ 2: –ü–æ–∏—Å–∫ –ø–æ –∫–ª–∞—Å—Å–∞–º (div –∏ article —Å –∫–ª–∞—Å—Å–∞–º–∏ product/offer/card)
        class_elements = soup.find_all(['div', 'article'], class_=lambda x: x and (
            'product' in x.lower() or 'offer' in x.lower() or 'card' in x.lower() or 
            'snippet' in x.lower() or 'item' in x.lower()
        ))
        if class_elements:
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(class_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –ø–æ –∫–ª–∞—Å—Å–∞–º")
            elements.extend(class_elements)
        
        # –ú–µ—Ç–æ–¥ 3: –ü–æ–∏—Å–∫ –ø–æ data-–∞—Ç—Ä–∏–±—É—Ç–∞–º —Å –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–º –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º
        data_elements = soup.find_all(attrs={"data-zone-name": re.compile(r"product|offer|snippet", re.I)})
        if data_elements:
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(data_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –ø–æ data-zone-name (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫)")
            elements.extend(data_elements)
        
        # –ú–µ—Ç–æ–¥ 4: –ü–æ–∏—Å–∫ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ (div —Å —Å—Å—ã–ª–∫–æ–π –∏ —Ü–µ–Ω–æ–π –≤–Ω—É—Ç—Ä–∏)
        # –ò—â–µ–º div, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Å—Å—ã–ª–∫—É –∏ —ç–ª–µ–º–µ–Ω—Ç —Å —Ü–µ–Ω–æ–π
        structural_elements = []
        for div in soup.find_all('div'):
            has_link = div.find('a', href=True)
            has_price = div.find(string=re.compile(r'[\d\s]+‚ÇΩ|[\d\s]+—Ä—É–±', re.I))
            if has_link and has_price:
                structural_elements.append(div)
        if structural_elements:
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(structural_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ (—Å—Å—ã–ª–∫–∞ + —Ü–µ–Ω–∞)")
            elements.extend(structural_elements)
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        seen = set()
        unique_elements = []
        for elem in elements:
            elem_id = id(elem)
            if elem_id not in seen:
                seen.add(elem_id)
                unique_elements.append(elem)
        
        logger.info(f"–ò—Ç–æ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(unique_elements)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤")
        return unique_elements
    
    def _parse_product_element(self, element, query: str) -> Optional[ProductData]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ —Ç–æ–≤–∞—Ä–∞"""
        try:
            # –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ - –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã
            title = ""
            
            # –°–ø–æ—Å–æ–± 1: –ü–æ–∏—Å–∫ –≤ data-zone-name="title"
            title_elem = element.find(attrs={"data-zone-name": re.compile(r"title|name", re.I)})
            if title_elem:
                title = title_elem.get_text(strip=True)
            
            # –°–ø–æ—Å–æ–± 2: –ü–æ–∏—Å–∫ —Å—Å—ã–ª–∫–∏ —Å —Ç–µ–∫—Å—Ç–æ–º
            if not title:
                link_elem = element.find('a', href=True)
                if link_elem:
                    title = link_elem.get_text(strip=True)
                    # –ï—Å–ª–∏ –≤ —Å—Å—ã–ª–∫–µ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ç–µ–∫—Å—Ç –≤ –¥–æ—á–µ—Ä–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö
                    if not title or len(title) < 3:
                        title_elem_in_link = link_elem.find(['span', 'div', 'h3', 'h4'], class_=re.compile(r'title|name', re.I))
                        if title_elem_in_link:
                            title = title_elem_in_link.get_text(strip=True)
            
            # –°–ø–æ—Å–æ–± 3: –ü–æ–∏—Å–∫ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            if not title or len(title) < 3:
                for tag in ['h3', 'h4', 'h2']:
                    title_elem = element.find(tag)
                    if title_elem:
                        title = title_elem.get_text(strip=True)
                        if title and len(title) >= 3:
                            break
            
            # –°–ø–æ—Å–æ–± 4: –ü–æ–∏—Å–∫ –ø–æ –∫–ª–∞—Å—Å–∞–º
            if not title or len(title) < 3:
                title_elem = (
                    element.find('span', class_=re.compile(r'title|name', re.I)) or
                    element.find('div', class_=re.compile(r'title|name', re.I))
                )
                if title_elem:
                    title = title_elem.get_text(strip=True)
            
            # –°–ø–æ—Å–æ–± 5: –ò–∑ –∞—Ç—Ä–∏–±—É—Ç–æ–≤
            if not title or len(title) < 3:
                title = element.get('aria-label', '') or element.get('title', '') or element.get('data-title', '')
            
            if not title or len(title) < 3:
                logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –≤ —ç–ª–µ–º–µ–Ω—Ç–µ")
                return None
            
            # –¶–µ–Ω–∞ - –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã
            price = 0
            
            # –°–ø–æ—Å–æ–± 1: –ü–æ–∏—Å–∫ –≤ data-zone-name="price"
            price_elem = element.find(attrs={"data-zone-name": re.compile(r"price", re.I)})
            if price_elem:
                price_text = price_elem.get_text(strip=True)
                price_match = re.search(r'[\d\s]+', price_text.replace(' ', '').replace('\u2009', '').replace(',', ''))
                if price_match:
                    try:
                        price = float(price_match.group().replace(' ', '').replace('\u2009', '').replace(',', ''))
                    except ValueError:
                        pass
            
            # –°–ø–æ—Å–æ–± 2: –ü–æ–∏—Å–∫ –ø–æ –∫–ª–∞—Å—Å–∞–º
            if price <= 0:
                price_elem = (
                    element.find('span', class_=re.compile(r'price', re.I)) or
                    element.find('div', class_=re.compile(r'price', re.I)) or
                    element.find('span', class_=re.compile(r'value|amount', re.I))
                )
                if price_elem:
                    price_text = price_elem.get_text(strip=True)
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ –∏–∑ —Ü–µ–Ω—ã (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã)
                    price_match = re.search(r'[\d\s,]+', price_text.replace(' ', '').replace('\u2009', '').replace(',', ''))
                    if price_match:
                        try:
                            price = float(price_match.group().replace(' ', '').replace('\u2009', '').replace(',', ''))
                        except ValueError:
                            pass
            
            # –°–ø–æ—Å–æ–± 3: –ü–æ–∏—Å–∫ —Ç–µ–∫—Å—Ç–∞ —Å —Ä—É–±–ª—è–º–∏/‚ÇΩ –≤ —ç–ª–µ–º–µ–Ω—Ç–µ
            if price <= 0:
                price_text_elem = element.find(string=re.compile(r'[\d\s]+‚ÇΩ|[\d\s]+—Ä—É–±', re.I))
                if price_text_elem:
                    price_text = price_text_elem.strip()
                    price_match = re.search(r'[\d\s]+', price_text.replace(' ', '').replace('\u2009', '').replace(',', ''))
                    if price_match:
                        try:
                            price = float(price_match.group().replace(' ', '').replace('\u2009', '').replace(',', ''))
                        except ValueError:
                            pass
            
            if price <= 0:
                logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ü–µ–Ω—É –¥–ª—è —Ç–æ–≤–∞—Ä–∞: {title[:50]}")
                return None
            
            # URL —Ç–æ–≤–∞—Ä–∞
            url = ""
            link_elem = element.find('a', href=True)
            if link_elem:
                url = link_elem.get('href', '')
                if url and not url.startswith('http'):
                    url = f"{self.BASE_URL}{url}" if url.startswith('/') else f"{self.BASE_URL}/{url}"
            
            if not url:
                # –§–æ—Ä–º–∏—Ä—É–µ–º URL –ø–æ–∏—Å–∫–∞ –∫–∞–∫ fallback
                url = f"{self.BASE_URL}/search?text={query}"
            
            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = ""
            img_elem = (
                element.find('img', src=True) or
                element.find('img', data_src=True) or
                element.find('img', data_lazy_src=True)
            )
            if img_elem:
                image = img_elem.get('src') or img_elem.get('data-src') or img_elem.get('data-lazy-src', '')
                if image and not image.startswith('http'):
                    image = f"https:{image}" if image.startswith('//') else image
            
            # –ë—Ä–µ–Ω–¥ –∏ –º–æ–¥–µ–ª—å –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è
            brand = ""
            model = ""
            
            # –°–ø–∏—Å–æ–∫ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤
            common_brands = [
                "Samsung", "Apple", "Xiaomi", "Huawei", "OnePlus", "Google", "Sony", "LG", 
                "ASUS", "Lenovo", "Honor", "Realme", "Oppo", "Vivo", "Nokia", "Motorola",
                "JBL", "Sennheiser", "Bose", "AirPods", "Beats", "HyperX", "Razer"
            ]
            
            title_lower = title.lower()
            for b in common_brands:
                if b.lower() in title_lower:
                    brand = b
                    # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –º–æ–¥–µ–ª—å –ø–æ—Å–ª–µ –±—Ä–µ–Ω–¥–∞
                    brand_pos = title_lower.find(b.lower())
                    if brand_pos >= 0:
                        model_part = title[brand_pos + len(b):].strip()
                        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ —Å–ª–æ–≤–∞ –∫–∞–∫ –º–æ–¥–µ–ª—å
                        model_words = model_part.split()[:3]
                        model = ' '.join(model_words).strip()
                    break
            
            # –ï—Å–ª–∏ –±—Ä–µ–Ω–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ –Ω–∞—á–∞–ª–∞ –Ω–∞–∑–≤–∞–Ω–∏—è
            words = title.split()  # –û–ø—Ä–µ–¥–µ–ª—è–µ–º words –∑–∞—Ä–∞–Ω–µ–µ
            if not brand and words:
                first_word = words[0]
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ—Ç —ç—Ç–æ –±—Ä–µ–Ω–¥
                if any(b.lower() == first_word.lower() for b in common_brands):
                    brand = first_word
                    model = ' '.join(words[1:4]) if len(words) > 1 else ""
            
            # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ—Ç –±—Ä–µ–Ω–¥–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –∫–∞–∫ –±—Ä–µ–Ω–¥
            if not brand and words:
                brand = words[0]
                model = ' '.join(words[1:4]) if len(words) > 1 else ""
            
            return ProductData(
                title=title,
                brand=brand or "–ù–µ —É–∫–∞–∑–∞–Ω",
                model=model or "–ù–µ —É–∫–∞–∑–∞–Ω–∞",
                price=price,
                shop_name="–Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç",
                url=url,
                image=image,
                description="",
                product_id="",
                scraped_at=datetime.utcnow()
            )
            
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —ç–ª–µ–º–µ–Ω—Ç–∞: {e}")
            return None
    
    def get_popular_products(self, category: str = "—ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞", limit: int = 10) -> List[ProductData]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
        
        Args:
            category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–æ–≤
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤
        
        Returns:
            –°–ø–∏—Å–æ–∫ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
        """
        search_queries = {
            "—ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞": ["—Å–º–∞—Ä—Ç—Ñ–æ–Ω", "—Ç–µ–ª–µ—Ñ–æ–Ω"],
            "–∫–æ–º–ø—å—é—Ç–µ—Ä—ã": ["–Ω–æ—É—Ç–±—É–∫", "–∫–æ–º–ø—å—é—Ç–µ—Ä"],
            "–∞—É–¥–∏–æ": ["–Ω–∞—É—à–Ω–∏–∫–∏", "–∫–æ–ª–æ–Ω–∫–∞"]
        }
        
        query = search_queries.get(category, ["—Å–º–∞—Ä—Ç—Ñ–æ–Ω"])[0]
        return self.search_products(query=query, limit=limit)

